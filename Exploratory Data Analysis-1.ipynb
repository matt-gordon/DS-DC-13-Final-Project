{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORATORY DATA ANALYSIS   \n",
    "Notebook containing my exploratory data analysis for the UCI Activities of Daily Living (ADL) data set.  Due to the number of plots generated, most will be output to file and compiled in a slide pack that will accompany this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in the csv saved from the File Extraction notebook that contains the accelerometer files for each activity\n",
    "dataset = pd.read_csv(\"../Data/MasterFileDF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspect how many data sets we have for each activity\n",
    "dataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based upon the number of datasets for 'eat_meat' and 'eat_soup', there would be insufficient samples to create a training and test set and therefore should be removed.  We could use these later in the model validation to see whether the model identifies them as an unknown activity. For the remainder of the exploratory data analysis, we'll keep all activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation\n",
    "Process the individual files in organise them for easy use during the feature engineering and model building phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function that ingests the UCI txt file, and converts each x,y,z stream to 'g' based upon the process\n",
    "# contained in MANUAL.txt\n",
    "\"\"\"\"\n",
    "Acceleration data recorded in the dataset are coded according to the following mapping:\n",
    "\t[0; +63] = [-1.5g; +1.5g]\n",
    "The conversion rule to extract the real acceleration value from the coded value is the following:\n",
    "\treal_val = -1.5g + (coded_val/63)*3g\n",
    "\"\"\"\"\"\n",
    "def convertAccel(filepath):\n",
    "    # open the file\n",
    "    df = pd.read_csv(filepath,sep=' ',names = ['x','y','z'],header=None)\n",
    "    # convert each value using equation\n",
    "    df = df.applymap(lambda x: -1.5 + (x/63.0)*3)\n",
    "    # output the file as filename-converted.txt\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to creates a list of tuples with format (filename,[accelerometer data],activity)\n",
    "\n",
    "def createTuple(filename):\n",
    "    filepath = '../Raw_Data/' + str(filename)  # create full file path to location of file in Data folder\n",
    "    df = convertAccel(filepath)  # return a 3 column dataframe of the converted x,y,z accelerations\n",
    "    activity = str(filename).split(\"-\")[7]  # extract the activity name from the filename string\n",
    "    output = (filename,(df.x,df.y,df.z),activity)\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function that loops through a dataframe of filenames and returns a list of tuples, one tuple for each filename\n",
    "def createDataList(fileDataframe):\n",
    "    dataList = []  # initialise a new empty list to fill with tuples\n",
    "    for ADL in fileDataframe.columns:  # loop through each activity column\n",
    "        for x in range(0,fileDataframe[ADL].count()): # loop through each filename that is a string (stops at NaN)\n",
    "            summary = createTuple(fileDataframe[ADL][x])  # create the filename summary tuple\n",
    "            dataList.append(summary)\n",
    "    return dataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a list of tuples, where each tuple is an activity file and the accelerometer data has been converted to g's\n",
    "dataList = createDataList(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Output an example of one of the tuples\n",
    "dataList[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accelerometer data is taken from a sensor unit mounted on the right hand of the subject with the x,y,z axes as shown in the image below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../image.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to calculate the root mean square\n",
    "def rms(x):   \n",
    "    return np.sqrt(x.dot(x)/x.size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to create all the model features; loop through each tuple in list\n",
    "def createFeatures(activityTuple):\n",
    "    \n",
    "    features = pd.DataFrame(index = range(0,len(activityTuple)),columns = ['x_max','y_max','z_max','tot_max', \\\n",
    "                                                                           'x_min','y_min','z_min','tot_min',\\\n",
    "                                                                           'x_mean','y_mean','z_mean','tot_mean',\\\n",
    "                                                                           'x_rms','y_rms','z_rms','tot_rms','totTime'\\\n",
    "                                                                           ,'activity'])\n",
    "    for row in range(0,len(activityTuple)):\n",
    "        x,y,z = activityTuple[row][1]\n",
    "        activity = activityTuple[row][2]\n",
    "        totAccel = (x**2 + y**2 + z**2)**0.5\n",
    "        features['x_max'][row] = float(np.max(x))\n",
    "        features['y_max'][row] = np.max(y)\n",
    "        features['z_max'][row] = np.max(z)\n",
    "        features['tot_max'][row] = np.max(totAccel)\n",
    "        features['x_min'][row] = np.min(x)\n",
    "        features['y_min'][row] = np.min(y)\n",
    "        features['z_min'][row] = np.min(z)\n",
    "        features['tot_min'][row] = np.min(totAccel)\n",
    "        features['x_mean'][row] = np.mean(x)\n",
    "        features['y_mean'][row] = np.mean(y)\n",
    "        features['z_mean'][row] = np.mean(z)\n",
    "        features['tot_mean'][row] = np.mean(totAccel)\n",
    "        features['x_rms'][row] = rms(x)\n",
    "        features['y_rms'][row] = rms(y)\n",
    "        features['z_rms'][row] = rms(z)\n",
    "        features['tot_rms'][row] = rms(totAccel)\n",
    "        features['totTime'][row] = len(x)*(1/32.0)  # The activity length in seconds is no. samples * 1/sampling rate\n",
    "        features['activity'][row] = str(activity)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a dataframe of features\n",
    "featuresDF = createFeatures(dataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featuresDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featuresDF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The features dataframe has been initialised as all objects whereas all columns other than activity should be float.  \n",
    "# Convert to correct data type so can create plots in exploratory analysis\n",
    "col_names = featuresDF.columns\n",
    "col_names = col_names[0:(len(col_names)-1)]  # drop activity from col_names\n",
    "featuresDF[col_names] = featuresDF[col_names].astype(float)\n",
    "featuresDF.activity = featuresDF.activity.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featuresDF.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Plots of Features and Raw Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop through the activities and generate X,Y,Z acceleration time series plots for each activity\n",
    "plt.ioff()\n",
    "for activity in dataset.columns:\n",
    "    dataList = []  # initialise a new empty list to fill with tuples\n",
    "    dfX = pd.DataFrame()\n",
    "    dfY = pd.DataFrame()\n",
    "    dfZ = pd.DataFrame()\n",
    "    for filename in dataset[activity].dropna():\n",
    "        output = createTuple(filename)     \n",
    "        dataList.append(output)\n",
    "    for row in range(0,len(dataList)):\n",
    "        x,y,z = dataList[row][1]\n",
    "        colNameX = \"X\"+ str(row)\n",
    "        colNameY = \"Y\"+ str(row)\n",
    "        colNameZ = \"Z\"+ str(row)\n",
    "        # Don't know why setting the column names in the dataframe initialisation isn't working\n",
    "        # interim fix, can come back later and correct this with more time to review\n",
    "        x_list = pd.DataFrame(x, dtype=float)\n",
    "        x_list.columns = [colNameX]\n",
    "        dfX = pd.concat([dfX,x_list],axis = 1)\n",
    "        y_list = pd.DataFrame(y, dtype=float)\n",
    "        y_list.columns = [colNameY]\n",
    "        dfY = pd.concat([dfY,y_list],axis = 1)\n",
    "        z_list = pd.DataFrame(z, dtype=float)\n",
    "        z_list.columns = [colNameZ]\n",
    "        dfZ = pd.concat([dfZ,z_list],axis = 1)\n",
    "    \n",
    "    #sns.set_style(\"white\")\n",
    "    sns.set(font_scale=2)\n",
    "    plt.figure(figsize=(18.5,10.5))\n",
    "    plt.plot(np.arange(0,len(dfX)*(1/32.0),(1/32.0)),dfX)\n",
    "    sns.axlabel('Seconds', 'Acceleration [g]')\n",
    "    title = activity + \" x accel\"\n",
    "    plt.title(title)\n",
    "    plt.savefig(\"../Plots/Time/\"+title +\".png\",dpi=200,facecolor='white')\n",
    "    plt.close()\n",
    "    plt.figure(figsize=(18.5,10.5))\n",
    "    plt.plot(np.arange(0,len(dfY)*(1/32.0),(1/32.0)), dfY)\n",
    "    sns.axlabel('Seconds', 'Acceleration [g]')\n",
    "    title = activity + \" y accel\"\n",
    "    plt.title(title)\n",
    "    plt.savefig(\"../Plots/Time/\"+title +\".png\",dpi=200)\n",
    "    plt.close()\n",
    "    plt.figure(figsize=(18.5,10.5))\n",
    "    plt.plot(np.arange(0,len(dfZ)*(1/32.0),(1/32.0)), dfZ)\n",
    "    sns.axlabel('Seconds', 'Acceleration [g]')\n",
    "    title = activity + \" z accel\"\n",
    "    plt.title(title)\n",
    "    plt.savefig(\"../Plots/Time/\"+title +\".png\",dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate Boxplots for each feature, grouped by activity and output to .png files in the Plots/Box/ folder\n",
    "plt.ioff()\n",
    "sns.set()\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_context(\"talk\")\n",
    "for name in col_names:\n",
    "    g = sns.boxplot(x=\"activity\", y=name, data=featuresDF)\n",
    "    plt.xticks(rotation=90) \n",
    "    g.set_title('boxplot of ' + name)\n",
    "    g.set_ylabel(\"Acceleration [g]\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"../Plots/Box/\"+str(name) +\".png\",dpi=200)\n",
    "    plt.close()\n",
    "plt.ion()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot a seaborn pairplot for relationship between features.  Save in Plots/Pair/ folder\n",
    "sns.set()\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "g = sns.pairplot(featuresDF)\n",
    "g.fig.title('Scatter Plot of Basic Features') \n",
    "g.set(xticklabels=[])\n",
    "g.set(yticklabels=[])\n",
    "plt.savefig(\"../Plots/Pair/\"+\"FeaturePairPlot.png\",dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For each feature, print a histogram for each activity for True/False (is/is not) that activity to see how \n",
    "# much the data overlaps and whether there are any good features that show good seperation between the two sets\n",
    "# save in Plots/Histo/ folder\n",
    "df = featuresDF\n",
    "\n",
    "plt.ioff()\n",
    "sns.set()\n",
    "sns.set(style=\"white\")\n",
    "sns.set_context(\"talk\")\n",
    "for feature in col_names:\n",
    "    for activity in df['activity'].unique():\n",
    "        fig,ax = plt.subplots()\n",
    "        fmax = int(df[feature][df['activity']==activity].max())+1\n",
    "        fmin = int(df[feature][df['activity']==activity].min())-1\n",
    "        binsize = np.arange(fmin,fmax,((fmax-fmin)/50.0))\n",
    "        sns.distplot(df[feature][df['activity']==activity],ax=ax,kde=False,label=('is '+ str(activity)),bins=binsize,\\\n",
    "                     color='b',norm_hist=True)\n",
    "        sns.distplot(df[feature][df['activity']!=activity],ax=ax,kde=False,label=('is not '+ str(activity)),\\\n",
    "                     bins=binsize,color='r',norm_hist=True)\n",
    "        plt.title(\"Histogram of \" + str(feature))\n",
    "        plt.legend(frameon=True)\n",
    "        plt.savefig(\"../Plots/Histo/\"+ str(activity)+\"-\"+str(feature)+\".png\",dpi=200)\n",
    "        plt.close()        \n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featuresDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
