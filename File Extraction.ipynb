{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FILE EXTRACTION & CATEGORIZATION\n",
    "#### by Matthew Gordon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Ingest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see if the UCI dataset has already been unzipped and the folder exists, if not unzip it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If the unzipped folder doesn't exists, open the zip file and \n",
    "# extract it to the current directory\n",
    "if not os.path.exists(r'HMP_Dataset'):\n",
    "    fh = open( '../ADL_Dataset.zip', 'rb')\n",
    "    z = zipfile.ZipFile(fh)\n",
    "    z.extractall()\n",
    "    fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see if a folder named Raw_Data already exists, if it doesn't, create the folder so that the individual activity files can be collated in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If the Raw_Data folder doesn't exist, create it\n",
    "newpath = r'../Raw_Data'\n",
    "if not os.path.exists(r'../Raw_Data'):\n",
    "    os.makedirs(newpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through a folder and subfolders and generate a list of files with their full file path and return it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_filepaths(directory):\n",
    "    \"\"\"\n",
    "    This function will generate the file names in a directory \n",
    "    tree by walking the tree either top-down or bottom-up. For each \n",
    "    directory in the tree rooted at directory top (including top itself), \n",
    "    it yields a 3-tuple (dirpath, dirnames, filenames).\n",
    "    \"\"\"\n",
    "    file_paths = []  # List which will store all of the full filepaths.\n",
    "\n",
    "    # Walk the tree.\n",
    "    for root, directories, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            # Join the two strings in order to form the full filepath.\n",
    "            filepath = os.path.join(root, filename)\n",
    "            file_paths.append(filepath)  # Add it to the list.\n",
    "\n",
    "    return file_paths  # Self-explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Search through the folder and create a list of all files  \n",
    "full_file_paths = get_filepaths(os.getcwd() + '/HMP_Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through the list and if it's a .txt file, move it to the Raw_Data file unless it is marked as a MODEL file;  Once complete, delete the HMP_Dataset folder and remaining files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop through the file list and move .txt files to Raw_Data folder; MODEL folder contains duplicates so ignore\n",
    "dst = '../Raw_Data'\n",
    "df = pd.DataFrame(list(full_file_paths),columns=['filename'])\n",
    "for f in df.filename.unique():\n",
    "    if 'MODEL' not in f:\n",
    "        if f.endswith(\".txt\"):\n",
    "            #f = \"~\" + f\n",
    "            shutil.move(f, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Delete the folder that was extracted from the .zip file; folder only contains duplicates\n",
    "shutil.rmtree('HMP_Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the list of files saved in the Raw_Data folder into a Pandas Dataframe of filepaths, organized by activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a list of filenames in the mypath directory\n",
    "mypath = '../Raw_Data/'\n",
    "\n",
    "txt_file_list = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a pandas dataframe where column is a list of filenames for datasets for that activity\n",
    "# we'll use this to then conduct some summary statistics on number of files for each activity\n",
    "# and then use it to create a randomised train and test dataset for each activity\n",
    "Activity_List = ['standup_chair','sitdown_chair','comb_hair','walk','descend_stairs','drink_glass', \\\n",
    "                 'eat_meat','eat_soup','pour_water','liedown_bed','getup_bed','use_telephone','brush_teeth']\n",
    "dataset = pd.DataFrame()\n",
    "fileList = []\n",
    "\n",
    "for activity in Activity_List: # loop through the file list for each activity\n",
    "    for f in txt_file_list: # loop through the file list\n",
    "        if 'Accelerometer' in f: # only consider filenames starting with Accelerometer\n",
    "            if activity in f: \n",
    "                fileList.append(f)\n",
    "    fileList = pd.DataFrame(fileList,columns=[activity],dtype=object) # turn list into dataframe\n",
    "    dataset = pd.concat([dataset,fileList], axis=1) # concatenate the single col df to master df\n",
    "    fileList = [] # clear the fileList before looping through again for next activity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframe to the file: MasterFile.csv for future use to avoid having to continuously re-run this Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output the filename dataframe to a csv to be re-used by other analysis\n",
    "# steps to avoid needing to run this notebook every time\n",
    "dataset.to_csv('../Data/MasterFileDF.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
